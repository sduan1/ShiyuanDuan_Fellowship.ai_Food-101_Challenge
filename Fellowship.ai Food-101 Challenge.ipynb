{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fellowship.ai Food-101 Challenge Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shiyuan Duan\n",
    "\n",
    "Date: 07/05/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction\n",
    "This report is a Fellowship.ai challenge. This report shows my knowlege in python and deeplearning, espicially in CV(Feel free to read my other repos that also demonstrates my interests in deep learning). \n",
    "The goal of this project is to construct an image classifier >85% accuracy to classify food images selected from 101 categories. In this report, I will explain the process of solving this challenging problem and demonstrate my thought process. I attempted transfer learning but only reached an accuracy of 82%. I then reached an accuracy of 85.49% by fine-tuning the entire model. I will include code in this report just for demonstration purposes. Please refer to other notebooks to see the outputs as rerunning the entire pipeline is too computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: First attempt with transfer learning (Only reached 82% accuracy)\n",
    "For this project, I am using a ResNet50 as suggested. ResNet50 is suitable for this problem because it is deep enough to extract complicated features, and it is capable of avoiding gradient vanishes/explode problems. Pytorch has ResNet50 pretrained on imagenet 1000 datasets. Therefore, my first attempt is to adopt a transfer learning method. I trained the model for 100 epochs and only reached an accuracy of 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Re-orgnize dataset\n",
    "My first step is to re-orgnize the dataset by spliting images into train and test folders according to train.txt and test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "relative_path = './food-101/images/'\n",
    "with open('food-101/meta/labels.txt','r') as lable_file:\n",
    "    labels = lable_file.read().split('\\n')\n",
    "labels = [x for x in labels if x != '']\n",
    "\n",
    "# Create train folder and move train images into it\n",
    "for label in labels:\n",
    "    label = label.lower().replace(' ', '_') \n",
    "    os.makedirs('./food-101/train/'+label)\n",
    "    \n",
    "with open('food-101/meta/train.txt','r') as train_file:\n",
    "    train_img_dirs = train_file.read().split('\\n')\n",
    "train_img_dirs = [x+'.jpg' for x in train_img_dirs if x != '']\n",
    "\n",
    "for img_dir in train_img_dirs:\n",
    "    label = img_dir.split('/')[0]\n",
    "    sourse = relative_path+img_dir\n",
    "    dest = './food-101/train/'+label\n",
    "    shutil.move(sourse, dest)\n",
    "    \n",
    "# Create test folder and move train images into it\n",
    "with open('food-101/meta/test.txt','r') as train_file:\n",
    "    train_img_dirs = train_file.read().split('\\n')\n",
    "    \n",
    "train_img_dirs = [x+'.jpg' for x in train_img_dirs if x != '']\n",
    "for img_dir in train_img_dirs:\n",
    "    label = img_dir.split('/')[0]\n",
    "    sourse = relative_path+img_dir\n",
    "    dest = './food-101/test/'+label\n",
    "    shutil.move(sourse, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load dataset and pretrained resnet50 to perform transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data augmentation, I am using RandomResizedCrop, RandomHorizontalFlip, RandomVerticalFlip, RandomRotation, and RandomAffine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomAffine(45),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datasets and dataloaders and other util parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder('./food-101/train', data_transforms['train'])\n",
    "test_set = datasets.ImageFolder('./food-101/test', data_transforms['test'])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "class_names = train_set.classes\n",
    "train_set_size = len(train_set)\n",
    "test_set_size = len(test_set)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download pretrained resnet50 and re-construct the fc layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "fc_input = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_input, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, len(class_names))\n",
    ")\n",
    "# Set requires_grad True only to fc layers and freezing other layers \n",
    "for name, param in resnet50.named_parameters():\n",
    "    param.requires_grad = 'fc' in name\n",
    "\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters optimizers, and learn rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(resnet50.parameters(), lr=0.01, momentum = 0.9)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min', patience = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    #train\n",
    "    resnet50.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer_ft.zero_grad()\n",
    "        \n",
    "        output = resnet50(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    #eval\n",
    "    resnet50.eval()\n",
    "    test_running_loss = 0.0\n",
    "    test_running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = resnet50(images)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            test_running_loss += loss.item() * images.size(0)\n",
    "            test_running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    epoch_loss = running_loss / train_set_size\n",
    "    epoch_acc = running_corrects.double() / train_set_size\n",
    "    print('epoch: {} Train_Loss: {:.4f} Train_Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
    "    print('test_acc: {:.4f}'.format(test_running_corrects.double()/test_set_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Result of transfer learning\n",
    "Transfer learning only reached accuarcy of 82% before overfitting. In order to achive a better result. I decided to fine-tune the entire model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Second attempt: Fine-tuning\n",
    "Transfer learning did not reach the desired accuracy. I suspect that the pre-trained feature extractor is not representative enough for the food-101 dataset. Therefore my second attempt is to fine-tune the model by training the entire pretrained model. \n",
    "\n",
    "Fine-tuning the model requires much more computational power. To avoid wasting time and computational power, I split the entire training pipeline into several checkpoints. After each checkpoint, I evaluate the model and make adjustments on data preprocessing and hyper-parameters. \n",
    "\n",
    "Initially, my idea was to fine-tune the last layer only because I believe that the first layers are just simple features like lines and edges. I reached an accuracy of 84% before over-fitting the model. I then unfroze the entire model and increased image resolution. Finally, I reached an accuracy of 85.49%, and the result is shown in the final-checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shown how I train the model at each check points. The output shown at the last cell is obtained by training from checkpoint 5 and saved as checkpoint 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import copy\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(448),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomAffine(45),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "train_set = datasets.ImageFolder('./food-101/train', data_transforms['train'])\n",
    "test_set = datasets.ImageFolder('./food-101/test', data_transforms['test'])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "class_names = train_set.classes\n",
    "train_set_size = len(train_set)\n",
    "test_set_size = len(test_set)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "resnet50_cp5 = models.resnet50(pretrained = True)\n",
    "resnet50_cp5.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 101)\n",
    ")\n",
    "resnet50_cp5 = resnet50_cp5.to(device)\n",
    "\n",
    "\n",
    "resnet50_cp5.load_state_dict(torch.load('PATH_TO_PREVIOUS_CHECK_POINT'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4609 Acc: 0.8739\n",
      "test: acc: 0.8441, current best acc: 0.8441\n",
      "Loss: 0.4547 Acc: 0.8751\n",
      "test: acc: 0.8464, current best acc: 0.8464\n",
      "Loss: 0.4442 Acc: 0.8791\n",
      "test: acc: 0.8493, current best acc: 0.8493\n",
      "Loss: 0.4449 Acc: 0.8791\n",
      "test: acc: 0.8549, current best acc: 0.8549\n"
     ]
    }
   ],
   "source": [
    "## Last check point cell\n",
    "max_epoch = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(resnet50_cp5.parameters(), lr=0.01, momentum = 0.9)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min', patience = 5)\n",
    "\n",
    "best_eval_acc = 0\n",
    "best_eval_dict = copy.deepcopy(resnet50_cp5.state_dict())\n",
    "while best_eval_acc <= 0.85:\n",
    "    #train\n",
    "    resnet50_cp5.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer_ft.zero_grad()\n",
    "        \n",
    "        output = resnet50_cp5(images)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "    #eval\n",
    "    resnet50_cp5.eval()\n",
    "    test_running_loss = 0.0\n",
    "    test_running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer_ft.zero_grad()\n",
    "\n",
    "            output = resnet50_cp5(images)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            test_running_loss += loss.item() * images.size(0)\n",
    "            test_running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    \n",
    "    best_eval_acc = max(best_eval_acc, test_running_corrects.double()/test_set_size)    \n",
    "    epoch_loss = running_loss / train_set_size\n",
    "    epoch_acc = running_corrects.double() / train_set_size\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    print('test: acc: {:.4f}, current best acc: {:.4f}'.format(test_running_corrects.double()/test_set_size, best_eval_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this challenge, I successfully trained a resnet50 that reaches 85.49% accuracy on food-101 dataset. The trianing pipeline is:\n",
    "\n",
    "1. transfer learning for 30 epoches\n",
    "2. fine-tune for 50 epoches with 224*224 image resolution (acc: 82.00%)\n",
    "3. fine-tune for 33 epoches with 512*512 image resolution (acc: 85.49%)\n",
    "\n",
    "Total: 113 epoches trained.\n",
    "If more time and computational power was granted. I would like to explore a better pipeline that can reach the same accuracy with fewer epoches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
